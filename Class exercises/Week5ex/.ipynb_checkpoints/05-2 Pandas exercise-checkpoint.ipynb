{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Class exercise slicing dataframe\n",
    "Using the file: befkbhalderstatkode.csv \n",
    "Use this data:\n",
    "```python\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "```\n",
    "1. wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result: (Hint: print(df);print(df.index);print(df.columns):     \n",
    "\n",
    "``` \n",
    "     Col1 Col2 col3  \n",
    "Row1    1    2    3\n",
    "Row2    4    5    6\n",
    "Row3    7    8    9\n",
    "\n",
    "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
    "Index(['Col1', 'Col2', 'col3'], dtype='object')\n",
    "```\n",
    "(Hint: use the pd.DataFrame(data=, columns=, index=) arguments)\n",
    "2. Make slices of data:\n",
    "   1. second column using column name\n",
    "   2. third column using column index (.iloc[])\n",
    "   3. slice element at third row of second column (use .iloc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Col1 Col2 col3\n",
      "Row1    1    2    3\n",
      "Row2    4    5    6\n",
      "Row3    7    8    9\n",
      "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
      "Index(['Col1', 'Col2', 'col3'], dtype='object') \n",
      "\n",
      "A. second column using column name\n",
      " Row1    2\n",
      "Row2    5\n",
      "Row3    8\n",
      "Name: Col2, dtype: object \n",
      "\n",
      "B. third column using column index (.iloc[])\n",
      " Row1    3\n",
      "Row2    6\n",
      "Row3    9\n",
      "Name: col3, dtype: object \n",
      "\n",
      "C. slice element at third row of second column (use .iloc())\n",
      " Row3    8\n",
      "Name: Col2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "\n",
    "df = pd.DataFrame(data=data[1:,1:],\n",
    "                  index=data[1:,0],\n",
    "                  columns=data[0,1:])\n",
    "\n",
    "print(df);print(df.index);print(df.columns, '\\n')\n",
    "print('A. second column using column name\\n', df['Col2'], '\\n')\n",
    "print('B. third column using column index (.iloc[])\\n', df.iloc[:,2], '\\n')\n",
    "print('C. slice element at third row of second column (use .iloc())\\n', df.iloc[2:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercise Pandas Data Series\n",
    "The CO2 Emission data set above is not updated since 2014\n",
    "1. Create a Pandas Series with emission data from 2014 for each country or region\n",
    "2. Find the 10 Countries/Regions with the highest emissions in 2014 and show emission numbers (reverse sorted)\n",
    "3. Remove if you can those rows that are not countries (regions and aggregated groups)\n",
    "    - Find the 10 countries with highest emissions in 2014\n",
    "4. Plot the emissions of China and USA over time respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../../data/API_EN.ATM.CO2E.KT_DS2_en_csv_v2_887574.csv', skiprows=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
